{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "import pandas\n",
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Data_Spectrograms.pkl', 'rb') as f:\n",
    "    X, y = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "y = keras.utils.to_categorical(y, num_classes=6)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a, X_train_b = numpy.split(X_train, 2, axis=1)\n",
    "X_test_a, X_test_b = numpy.split(X_test, 2, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_a = numpy.squeeze(X_train_a)\n",
    "X_train_b = numpy.squeeze(X_train_b)\n",
    "X_test_a = numpy.squeeze(X_test_a)\n",
    "X_test_b = numpy.squeeze(X_test_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv1D, MaxPooling1D, Flatten, concatenate\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "def build_model():\n",
    "    model = Sequential()\n",
    "    model.add(Conv1D(32, kernel_size=4, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01),\n",
    "                     input_shape=(100,30)))\n",
    "    model.add(MaxPooling1D(2,2))\n",
    "    model.add(Conv1D(32, kernel_size=4, kernel_regularizer=keras.regularizers.l2(0.01), activation='relu'))\n",
    "    model.add(Conv1D(32, kernel_size=4, kernel_regularizer=keras.regularizers.l2(0.01), activation='relu'))\n",
    "    model.add(MaxPooling1D(2,2))\n",
    "    model.add(Conv1D(32, kernel_size=4, activation='relu'))\n",
    "    model.add(MaxPooling1D(2,2))\n",
    "    model.add(Conv1D(32, kernel_size=4, activation='relu'))\n",
    "    model.add(Flatten())\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bramd\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\bramd\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\bramd\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\bramd\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_a = build_model()\n",
    "model_b = build_model()\n",
    "combined_output = concatenate([model_a.output, model_b.output])\n",
    "merged_layers = Dense(128, activation='relu')(combined_output)\n",
    "merged_layers = Dense(6, activation='softmax')(merged_layers)\n",
    "model = Model(inputs=[model_a.input, model_b.input], outputs=merged_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bramd\\Anaconda3\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From C:\\Users\\bramd\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.compile(optimizer=Adam(lr=0.001, decay=0.001/80), loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\bramd\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "WARNING:tensorflow:From C:\\Users\\bramd\\Anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "Train on 13837 samples, validate on 1538 samples\n",
      "Epoch 1/80\n",
      "13837/13837 [==============================] - 7s 484us/step - loss: 2.5807 - acc: 0.6041 - val_loss: 1.7523 - val_acc: 0.7048\n",
      "Epoch 2/80\n",
      "13837/13837 [==============================] - 5s 380us/step - loss: 1.5876 - acc: 0.7062 - val_loss: 1.3229 - val_acc: 0.7419\n",
      "Epoch 3/80\n",
      "13837/13837 [==============================] - 5s 354us/step - loss: 1.2363 - acc: 0.7393 - val_loss: 1.1509 - val_acc: 0.7458\n",
      "Epoch 4/80\n",
      "13837/13837 [==============================] - 5s 353us/step - loss: 1.0414 - acc: 0.7640 - val_loss: 0.9811 - val_acc: 0.7594\n",
      "Epoch 5/80\n",
      "13837/13837 [==============================] - 5s 370us/step - loss: 0.9705 - acc: 0.7703 - val_loss: 1.0262 - val_acc: 0.7620\n",
      "Epoch 6/80\n",
      "13837/13837 [==============================] - 5s 348us/step - loss: 0.8928 - acc: 0.7737 - val_loss: 0.8011 - val_acc: 0.7919\n",
      "Epoch 7/80\n",
      "13837/13837 [==============================] - 5s 347us/step - loss: 0.8173 - acc: 0.7860 - val_loss: 0.8237 - val_acc: 0.7711\n",
      "Epoch 8/80\n",
      "13837/13837 [==============================] - 5s 369us/step - loss: 0.7580 - acc: 0.8002 - val_loss: 0.7255 - val_acc: 0.8036\n",
      "Epoch 9/80\n",
      "13837/13837 [==============================] - 5s 345us/step - loss: 0.7799 - acc: 0.7841 - val_loss: 0.7012 - val_acc: 0.7952\n",
      "Epoch 10/80\n",
      "13837/13837 [==============================] - 5s 348us/step - loss: 0.6869 - acc: 0.8089 - val_loss: 0.6982 - val_acc: 0.8134\n",
      "Epoch 11/80\n",
      "13837/13837 [==============================] - 5s 379us/step - loss: 0.6625 - acc: 0.8167 - val_loss: 0.6786 - val_acc: 0.7802\n",
      "Epoch 12/80\n",
      "13837/13837 [==============================] - 6s 435us/step - loss: 0.6372 - acc: 0.8161 - val_loss: 0.6385 - val_acc: 0.8153\n",
      "Epoch 13/80\n",
      "13837/13837 [==============================] - 5s 362us/step - loss: 0.6068 - acc: 0.8240 - val_loss: 0.6325 - val_acc: 0.8121\n",
      "Epoch 14/80\n",
      "13837/13837 [==============================] - 5s 369us/step - loss: 0.5812 - acc: 0.8266 - val_loss: 0.6737 - val_acc: 0.7906\n",
      "Epoch 15/80\n",
      "13837/13837 [==============================] - 5s 363us/step - loss: 0.6030 - acc: 0.8212 - val_loss: 0.5842 - val_acc: 0.8134\n",
      "Epoch 16/80\n",
      "13837/13837 [==============================] - 6s 457us/step - loss: 0.5768 - acc: 0.8295 - val_loss: 0.6853 - val_acc: 0.7893\n",
      "Epoch 17/80\n",
      "13837/13837 [==============================] - 6s 414us/step - loss: 0.6441 - acc: 0.8148 - val_loss: 0.6730 - val_acc: 0.8023\n",
      "Epoch 18/80\n",
      "13837/13837 [==============================] - 6s 408us/step - loss: 0.6597 - acc: 0.8156 - val_loss: 0.6822 - val_acc: 0.7958\n",
      "Epoch 19/80\n",
      "13837/13837 [==============================] - 5s 370us/step - loss: 0.6075 - acc: 0.8275 - val_loss: 0.6419 - val_acc: 0.8147\n",
      "Epoch 20/80\n",
      "13837/13837 [==============================] - 6s 442us/step - loss: 0.5780 - acc: 0.8344 - val_loss: 0.6202 - val_acc: 0.8192\n",
      "Epoch 21/80\n",
      "13837/13837 [==============================] - 5s 369us/step - loss: 0.5539 - acc: 0.8407 - val_loss: 0.5832 - val_acc: 0.8199\n",
      "Epoch 22/80\n",
      "13837/13837 [==============================] - 5s 364us/step - loss: 0.5550 - acc: 0.8416 - val_loss: 0.5815 - val_acc: 0.8303\n",
      "Epoch 23/80\n",
      "13837/13837 [==============================] - 5s 378us/step - loss: 0.5052 - acc: 0.8533 - val_loss: 0.5759 - val_acc: 0.8199\n",
      "Epoch 24/80\n",
      "13837/13837 [==============================] - 5s 360us/step - loss: 0.4856 - acc: 0.8597 - val_loss: 0.5764 - val_acc: 0.8101\n",
      "Epoch 25/80\n",
      "13837/13837 [==============================] - 5s 374us/step - loss: 0.4898 - acc: 0.8548 - val_loss: 0.5483 - val_acc: 0.8309\n",
      "Epoch 26/80\n",
      "13837/13837 [==============================] - 7s 492us/step - loss: 0.5214 - acc: 0.8467 - val_loss: 0.6081 - val_acc: 0.8140\n",
      "Epoch 27/80\n",
      "13837/13837 [==============================] - 7s 482us/step - loss: 0.5513 - acc: 0.8420 - val_loss: 0.6307 - val_acc: 0.8186\n",
      "Epoch 28/80\n",
      "13837/13837 [==============================] - 7s 473us/step - loss: 0.5386 - acc: 0.8480 - val_loss: 0.5973 - val_acc: 0.8251\n",
      "Epoch 29/80\n",
      "13837/13837 [==============================] - 5s 378us/step - loss: 0.4956 - acc: 0.8591 - val_loss: 0.5988 - val_acc: 0.8244\n",
      "Epoch 30/80\n",
      "13837/13837 [==============================] - 6s 401us/step - loss: 0.5074 - acc: 0.8558 - val_loss: 0.5770 - val_acc: 0.8342\n",
      "Epoch 31/80\n",
      "13837/13837 [==============================] - 5s 396us/step - loss: 0.4672 - acc: 0.8672 - val_loss: 0.6078 - val_acc: 0.8264\n",
      "Epoch 32/80\n",
      "13837/13837 [==============================] - 5s 397us/step - loss: 0.4583 - acc: 0.8693 - val_loss: 0.5443 - val_acc: 0.8440\n",
      "Epoch 33/80\n",
      "13837/13837 [==============================] - 5s 366us/step - loss: 0.5055 - acc: 0.8643 - val_loss: 0.5882 - val_acc: 0.8277\n",
      "Epoch 34/80\n",
      "13837/13837 [==============================] - 6s 447us/step - loss: 0.4725 - acc: 0.8680 - val_loss: 0.6174 - val_acc: 0.8160\n",
      "Epoch 35/80\n",
      "13837/13837 [==============================] - 6s 417us/step - loss: 0.4687 - acc: 0.8686 - val_loss: 0.6302 - val_acc: 0.8231\n",
      "Epoch 36/80\n",
      "13837/13837 [==============================] - 5s 386us/step - loss: 0.4749 - acc: 0.8729 - val_loss: 0.5760 - val_acc: 0.8388\n",
      "Epoch 37/80\n",
      "13837/13837 [==============================] - 6s 418us/step - loss: 0.4364 - acc: 0.8777 - val_loss: 0.5836 - val_acc: 0.8316\n",
      "Epoch 38/80\n",
      "13837/13837 [==============================] - 5s 381us/step - loss: 0.4232 - acc: 0.8796 - val_loss: 0.5856 - val_acc: 0.8303\n",
      "Epoch 39/80\n",
      "13837/13837 [==============================] - 5s 395us/step - loss: 0.4077 - acc: 0.8877 - val_loss: 0.5803 - val_acc: 0.8446\n",
      "Epoch 40/80\n",
      "13837/13837 [==============================] - 6s 410us/step - loss: 0.4176 - acc: 0.8806 - val_loss: 0.5692 - val_acc: 0.8407\n",
      "Epoch 41/80\n",
      "13837/13837 [==============================] - 5s 389us/step - loss: 0.4240 - acc: 0.8803 - val_loss: 0.5883 - val_acc: 0.8283\n",
      "Epoch 42/80\n",
      "13837/13837 [==============================] - 5s 391us/step - loss: 0.3844 - acc: 0.8908 - val_loss: 0.5970 - val_acc: 0.8316\n",
      "Epoch 43/80\n",
      "13837/13837 [==============================] - 6s 407us/step - loss: 0.3846 - acc: 0.8926 - val_loss: 0.6413 - val_acc: 0.8349\n",
      "Epoch 44/80\n",
      "13837/13837 [==============================] - 5s 386us/step - loss: 0.3726 - acc: 0.8885 - val_loss: 0.5843 - val_acc: 0.8277\n",
      "Epoch 45/80\n",
      "13837/13837 [==============================] - 5s 387us/step - loss: 0.3640 - acc: 0.8881 - val_loss: 0.5704 - val_acc: 0.8420\n",
      "Epoch 46/80\n",
      "13837/13837 [==============================] - 6s 413us/step - loss: 0.3235 - acc: 0.8979 - val_loss: 0.4980 - val_acc: 0.8472\n",
      "Epoch 47/80\n",
      "13837/13837 [==============================] - 5s 385us/step - loss: 0.3076 - acc: 0.9017 - val_loss: 0.5488 - val_acc: 0.8492\n",
      "Epoch 48/80\n",
      "13837/13837 [==============================] - 5s 393us/step - loss: 0.3365 - acc: 0.8959 - val_loss: 0.5592 - val_acc: 0.8401\n",
      "Epoch 49/80\n",
      "13837/13837 [==============================] - 6s 405us/step - loss: 0.3084 - acc: 0.9004 - val_loss: 0.5462 - val_acc: 0.8472\n",
      "Epoch 50/80\n",
      "13837/13837 [==============================] - 5s 387us/step - loss: 0.2937 - acc: 0.9087 - val_loss: 0.5459 - val_acc: 0.8459\n",
      "Epoch 51/80\n",
      "13837/13837 [==============================] - 5s 390us/step - loss: 0.3103 - acc: 0.9017 - val_loss: 0.5329 - val_acc: 0.8440\n",
      "Epoch 52/80\n",
      "13837/13837 [==============================] - 6s 408us/step - loss: 0.3156 - acc: 0.9068 - val_loss: 0.6008 - val_acc: 0.8472\n",
      "Epoch 53/80\n",
      "13837/13837 [==============================] - 5s 388us/step - loss: 0.3689 - acc: 0.9001 - val_loss: 0.6592 - val_acc: 0.8381\n",
      "Epoch 54/80\n",
      "13837/13837 [==============================] - 5s 391us/step - loss: 0.3287 - acc: 0.9000 - val_loss: 0.5685 - val_acc: 0.8453\n",
      "Epoch 55/80\n",
      "13837/13837 [==============================] - 6s 402us/step - loss: 0.2952 - acc: 0.9090 - val_loss: 0.5660 - val_acc: 0.8433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 56/80\n",
      "13837/13837 [==============================] - 5s 390us/step - loss: 0.3166 - acc: 0.9077 - val_loss: 0.5686 - val_acc: 0.8420\n",
      "Epoch 57/80\n",
      "13837/13837 [==============================] - 5s 387us/step - loss: 0.3102 - acc: 0.9066 - val_loss: 0.5639 - val_acc: 0.8420\n",
      "Epoch 58/80\n",
      "13837/13837 [==============================] - 7s 540us/step - loss: 0.2886 - acc: 0.9131 - val_loss: 0.5895 - val_acc: 0.8394\n",
      "Epoch 59/80\n",
      "13837/13837 [==============================] - 7s 494us/step - loss: 0.2659 - acc: 0.9196 - val_loss: 0.5730 - val_acc: 0.8479\n",
      "Epoch 60/80\n",
      "13837/13837 [==============================] - 6s 437us/step - loss: 0.2594 - acc: 0.9212 - val_loss: 0.6052 - val_acc: 0.8485\n",
      "Epoch 61/80\n",
      "13837/13837 [==============================] - 6s 424us/step - loss: 0.2501 - acc: 0.9240 - val_loss: 0.5720 - val_acc: 0.8433\n",
      "Epoch 62/80\n",
      "13837/13837 [==============================] - 6s 432us/step - loss: 0.2418 - acc: 0.9290 - val_loss: 0.6007 - val_acc: 0.8362\n",
      "Epoch 63/80\n",
      "13837/13837 [==============================] - 6s 428us/step - loss: 0.2400 - acc: 0.9286 - val_loss: 0.6020 - val_acc: 0.8407\n",
      "Epoch 64/80\n",
      "13837/13837 [==============================] - 5s 392us/step - loss: 0.2393 - acc: 0.9277 - val_loss: 0.6087 - val_acc: 0.8368\n",
      "Epoch 65/80\n",
      "13837/13837 [==============================] - 6s 421us/step - loss: 0.2324 - acc: 0.9287 - val_loss: 0.6284 - val_acc: 0.8459\n",
      "Epoch 66/80\n",
      "13837/13837 [==============================] - 5s 392us/step - loss: 0.2296 - acc: 0.9337 - val_loss: 0.6860 - val_acc: 0.8257\n",
      "Epoch 67/80\n",
      "13837/13837 [==============================] - 5s 397us/step - loss: 0.2465 - acc: 0.9282 - val_loss: 0.6222 - val_acc: 0.8531\n",
      "Epoch 68/80\n",
      "13837/13837 [==============================] - 6s 414us/step - loss: 0.2304 - acc: 0.9315 - val_loss: 0.6109 - val_acc: 0.8485\n",
      "Epoch 69/80\n",
      "13837/13837 [==============================] - 5s 395us/step - loss: 0.2260 - acc: 0.9350 - val_loss: 0.6687 - val_acc: 0.8336\n",
      "Epoch 70/80\n",
      "13837/13837 [==============================] - 6s 402us/step - loss: 0.2165 - acc: 0.9336 - val_loss: 0.7491 - val_acc: 0.8218\n",
      "Epoch 71/80\n",
      "13837/13837 [==============================] - 6s 418us/step - loss: 0.2026 - acc: 0.9412 - val_loss: 0.6541 - val_acc: 0.8433\n",
      "Epoch 72/80\n",
      "13837/13837 [==============================] - 5s 395us/step - loss: 0.2085 - acc: 0.9402 - val_loss: 0.6668 - val_acc: 0.8394\n",
      "Epoch 73/80\n",
      "13837/13837 [==============================] - 6s 397us/step - loss: 0.2064 - acc: 0.9394 - val_loss: 0.6852 - val_acc: 0.8336\n",
      "Epoch 74/80\n",
      "13837/13837 [==============================] - 6s 417us/step - loss: 0.1945 - acc: 0.9457 - val_loss: 0.7108 - val_acc: 0.8362\n",
      "Epoch 75/80\n",
      "13837/13837 [==============================] - 6s 444us/step - loss: 0.2290 - acc: 0.9321 - val_loss: 0.6472 - val_acc: 0.8414\n",
      "Epoch 76/80\n",
      "13837/13837 [==============================] - 6s 412us/step - loss: 0.1945 - acc: 0.9455 - val_loss: 0.6704 - val_acc: 0.8433\n",
      "Epoch 77/80\n",
      "13837/13837 [==============================] - 6s 456us/step - loss: 0.2093 - acc: 0.9404 - val_loss: 0.6423 - val_acc: 0.8401\n",
      "Epoch 78/80\n",
      "13837/13837 [==============================] - 5s 395us/step - loss: 0.1953 - acc: 0.9449 - val_loss: 0.7071 - val_acc: 0.8472\n",
      "Epoch 79/80\n",
      "13837/13837 [==============================] - 6s 427us/step - loss: 0.1834 - acc: 0.9493 - val_loss: 0.6985 - val_acc: 0.8433\n",
      "Epoch 80/80\n",
      "13837/13837 [==============================] - 5s 395us/step - loss: 0.2415 - acc: 0.9376 - val_loss: 0.7518 - val_acc: 0.8336\n"
     ]
    }
   ],
   "source": [
    "trained_model = model.fit([X_train_a, X_train_b], y_train,\n",
    "                          validation_data=([X_test_a, X_test_b], y_test),\n",
    "                          epochs=80, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1538/1538 [==============================] - 0s 145us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.7517802207615658, 0.8335500650195059]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate([X_test_a, X_test_b], y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
